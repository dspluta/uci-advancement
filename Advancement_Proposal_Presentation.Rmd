---
title: "Methods for High-dimensional Inference, with Applications to Imaging Genetics"
author: "Dustin Pluta"
date: "28 Mar 2018"
output:
  xaringan::moon_reader:
    css: ["hygge.css", "default", "default-fonts"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
#knitr::opts_knit$set(root.dir = "..")
```

```{r, include = FALSE}
library(tidyverse)
library(magrittr)
load("dat/dat_lm_results.RData")
load("dat/dat_gcta_results.RData")
```

layout: true
background-image: url(img/bg.png)
background-position: center
background-size: fill

---
background-image: url(img/seals_new.png) 
background-position: center
background-size: fill

# Acknowledgements

* __Gui Xue__, PI and data provider, Beijing Normal University, Center for Brain and Learning Sciences

* __Chuansheng Chen__, UCI, Dept. of Psychology and Social Behavior

* __Hernando Ombao__, KAUST, Dept. of Statistics

* __Zhaoxia Yu__, UCI, Dept. of Statistics

* __Tong Shen__, UCI, Dept. of Statistics (PhD Student)

---
## Overview of Talk

0. Scientific background of __connectome genetics__.

1. __Mantel test__ and metric-based association testing.

2. The __adaptive Mantel test__ for penalized inference.

3. Future Work: __Methods for dynamic connectivity__ and __manifold mixed effects model__.

***

### Links

- __Adaptive Mantel Test Paper:__ [arxiv.org/pdf/1712.07270.pdf](https://arxiv.org/pdf/1712.07270.pdf)

- __Slides available:__ [github.com/dspluta/Presentations/](https://github.com/dspluta/Presentations/)

- __Adaptive Mantel `R` Package:__ [github.com/dspluta/adamant](https://github.com/dspluta/adamant)


---
background-image:
class: center, inverse, middle

# Scientific Background of Connectome Genetics

---
## Scientific Background
.pull-left[.full-width[.content-box-yellow[__Connectome__<br><br>The total set of physical and functional relationships between all brain regions.]]]
.pull-right[.shadow[
```{r echo=FALSE, out.height="100%", out.width="100%"}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/visualizing_brain_connectivity_small.jpg")
```
]]

***

.full-width[.content-box-blue[__Functional Connectivity__<br><br>Measures the level of correspondence between activity in two regions, typically quantified by Pearson's correlation or coherence.]]

---
background-image: 
background-position: center
background-size: contain
class: center, inverse

# Functional Connectivity: Coherence

```{r echo=FALSE, out.height="150%", out.width="150%", fig.align='center', fig.pos='H'}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/Coh-Illustration2.jpg")
```


---
## Scientific Background
.pull-left[.full-width[.content-box-green[__Genome__<br><br>The set of all genes and genetic material in an organism.]]]
.pull-right[
```{r echo=FALSE, out.height="80%", out.width="80%"}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/UCSC_human_chromosome_colours_small.png")
```
]

***

.full-width[.content-box-green[__Single Nucleotide Polymorphisms (SNPs)__<br><br> Are locations in the DNA that exhibit particularly high variation across individuals (in humans).]]

---
background-image: url(img/snp_diagram_large.png)
background-position: center
background-size: contain
class: center, inverse

# SNPs

---
background-image: url(img/BIG_schematic.png)
background-position: center
background-size: contain
class: center

---
## Scientific Background

.full-width[.content-box-green[__Heritability__ of a phenotypic trait refers to the amount of variation of the trait that is explained by genetic effects.]]

.full-width[.content-box-orange[__Narrow-sense heritability__ $(h^2)$ refers to phenotypic variation explained just by _additive_ genetic effects only.]]

---
## Scientific Background

#### Estimating Heritability with Variance Components Model

* A popular approach to estimate narrow-sense heritability of a phenotype is the
_variance components_ (*random effects*) model.

$$Y = X b + \varepsilon,$$

with
* $\text{Var} (Y) = \sigma^2_{b}XX^T + \sigma^2_{\varepsilon}I_n$,

* $b \sim N(0, \sigma^2_{b}I_p)$ is a random vector of SNP effects,

* $\varepsilon \sim N(0, \sigma^2_{\varepsilon}I_n)$ residual vector,

* $X$ is the SNP data matrix (column centered and scaled).

---
## Scientific Background

#### Estimating Heritability with Variance Components Model

* The above random effects model can be rewritten as

$$Y = g + \varepsilon,$$

where $g \sim N(0, \sigma_g^2G)$, for $G = XX^T/p$ and $\sigma^2_g = p\sigma^2_{b}$.

__Narrow-sense heritability__ of the phenotype measured 
by $Y$ can then be estimated as 

$$\hat h^2 = \frac{\hat\sigma^2_g}{\hat \sigma^2_g + \hat\sigma^2_{\varepsilon}}.$$

$$\hat h^2 = \frac{\text{tr}\left(\hat\Sigma_g\right)}{\text{tr}\left(\hat \Sigma_g\right) + \text{tr}\left(\hat\Sigma_{\varepsilon}\right)},$$

where $\hat\Sigma_g = \hat\sigma^2_g G, \hat\Sigma_{\varepsilon} = \hat\sigma^2_{\varepsilon}I_n$.

---
background-image:
class: center, inverse, middle

# Mantel Test and Distance-based Association Testing

---
## Metric-based Association Testing

.full-width[.content-box-purple[__The Inference Goal__<br><br>Given observations of $n$ subjects across two data modalities __X__ and __Y__, is 
similarity in __X__ significantly associated with similarity in __Y__?]]

#### Setup

- In our application, $X \in \mathbf{X}^n$ is an $n \times p$ matrix of SNP measurements, and $Y \in \mathbf{Y}$ is an $n \times 1$ 
vector of scalar phenotype measurements.

- Assume $X$ and $Y$ have been column centered and scaled.

- A bounded, symmetric, positive semi-definite similarity function $\mathcal{K}$, e.g. $\mathcal{K}(u, v) = u^Tv$.

---
## Association Testing Methods

- __Mantel's test__ (Mantel 1967) uses the inner product of the pairwise distance/similarity matrices from $X$ and $Y$.

- The __RV coefficient__ (Escoufier 1976) uses a test statistic based on the multivariate correlation 
between $X$ and $Y$.

- The __distance covariance__ (dCov) test (Szekely, Rizzo, Bakirov, 2007) is defined 
as the covariance of distances between $X$ and $Y$.

- __Adaptive sum of powered score test__ (Xu et. al 2017).

***

#### Challenges

- These approaches suffer from __low power__ in high-dimensions,

- Generally __lack a rigorous methodology__ for chooosing the appropriate metrics and testing parameters and interpreting results,

- Powered alternatives can be difficult to determine.

---
## Mantel Test

* Given __similarity functions__ $\mathcal{K}_X: \mathbb R^P \times \mathbb{R}^P \to \mathbb{R}$
and $\mathcal{K}_Y: \mathbb{R} \times \mathbb{R} \to \mathbb{R}$, we can form two $n\times n$ __Gram matrices__ $K$ and $H$, where

$$K_{ij} = \mathcal{K}_X(X_i, X_j)$$
$$H_{ij} = \mathcal{K}_Y(Y_i, Y_j).$$

* The __correlation__ of these distance matrices is

$$r(H, K) := \frac{\langle K, H\rangle}{\|K\|\cdot\|H\|},$$

---
## Mantel Test

.full-width[.content-box-red[__How should we test the significance of the correlation?__]]

Mantel's original approach (1967) is to __permute__ rows and columns of one of the pairwise distance matrices to generate the reference distribution.

That is, for test statistic

$$T = \langle K, H\rangle = \sum_{i = 1}^n\sum_{j = 1}^n K_{ij}H_{ij} = \text{tr}(KH),$$

we compute the __permutation $P$-value__ by permuting $H$ to approximate the reference distribution.

---
background-image: url(img/Mantel_Diagram.png)
background-position: center
background-size: contain
class: inverse

---
## Mantel Test

#### Similarity with Weighted Inner Products

For two vectors $u, v \in \mathbb{R^p}$, the __weighted inner product__ $\langle \cdot, \cdot \rangle_{\mathcal{W}}$ for some positive semi-definite matrix $\mathcal{W}$, is defined as

$$\langle u, v \rangle_{\mathcal{W}} = u^T \mathcal{W} v.$$

The __Mantel Test Statistic__ for similarity $\langle \cdot, \cdot \rangle_{\mathcal{W}}$ is 

$$T_{\mathcal{W}} = \text{tr}(X\mathcal{W}X^TYY^T) = Y^TX\mathcal{W}X^TY.$$

--
count: false

***

.full-width[.content-box-yellow[__Question__<br><br>How does the choice of weight matrix affect the test characteristics?<br><br> How should the weight matrix be chosen?]]

---
## Weight Matrices

#### Euclidean Inner Product

- Choosing $\mathcal{W} = I_p$ gives $K = XX^T$, which is the Gram matrix for the standard Euclidean inner product.

#### Mahalanobis Similarity

- Choosing $\mathcal{W} = (X^TX)^{-1}$ gives $K = X(X^TX)^{-1}X^T$, which is a similarity matrix related to the Mahalanobis distance.

#### Comparison

- The Mahalnobis similarity adjusts for the covariance structure between features (columns) of $X$
 
---
class: center, middle, inverse
background-image: 

```{r echo=FALSE, out.height="80%", out.width="80%"}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/euclid_v_mahal_1.jpg")
```

---
class: center, middle, inverse
background-image: 

```{r echo=FALSE, out.height="80%", out.width="80%"}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/euclid_v_mahal_2.jpg")
```

---
class: center, middle, inverse
background-image: 

```{r echo=FALSE, out.height="80%", out.width="80%"}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/euclid_v_mahal_3.jpg")
```

--- 
## Weight Matrices

$$\begin{aligned}
\hline
\text{Metric}    & ~~~~~~~\text{Gram Matrix} & \text{Mantel Stat.} \\
\hline
\text{Euclidean} & ~~~~~~~~K_R = XX^T & T_R = \text{tr}(K_R H)\\
\text{Mahalanobis} & ~~~~~~~~K_F = X(X^TX)^{-1}X^T & T_F = \text{tr}(K_F H)\\
\text{Ridge Kernel} & ~~~~~~~~K_{\lambda} = X(X^TX + \lambda I)^{-1}X^T & T_{\lambda} = \text{tr}(K_{\lambda} H)\\
\hline
\end{aligned}$$

---
background-image: url(img/sample_scatter.jpg)
background-position: center
background-size: contain
class: center, inverse

---
background-image: url(img/dist_and_sim.png)
background-position: center
background-size: contain
class: center, inverse

---
background-image: url(img/Hernando&Dustin-Final-01.jpg)
background-position: center
background-size: contain
class: center, inverse

---
## Mantel Test

.full-width[.content-box-yellow[__Contributions__<br><br> **Derive testing properties** of the ridge kernel in the Mantel test. <br><br> **Link the random effects, fixed effects, and ridge regression score tests** through the kernel Mantel test framework. <br><br> **Develop the adaptive Mantel test** for simultaneous testing across a range of tuning parameters.]]

#### Advantages of Proposed Methods

- Provides an extremely flexible and computationally practical framework for testing 
a wide variety of relationships between different modalities.

- Simulations show the kernel Mantel test is often more powerful than competing methods.

---
## Mantel Test

#### Correlation of Similarities

Assume $\text{rank}(X) = r$ with singular value decomposition $X = U_{n\times r}D_{r\times r}V_{p\times r}^T$, where $\eta_j, j = 1, \cdots, r$ are the squared singular values. 
Let $H=YY^T$ and $Z = U^TY$.

__Euclidean Metric__ $~~~~~~~~~~~~r(H, K_R) = \frac{\sum_{j=1}^r\eta_j z_j^2}{\sqrt{\sum_{j=1}^r\eta_j^2}\sum_{i=1}^n y_i^2},$

__Mahalanobis Metric__ $~~~~~~~r(H, K_F) = \frac{\sum_{j=1}^r z_j^2}{\sqrt{p} \sum_{i=1}^n y_i^2},$
    	
__Ridge Similarity__ $~~~~~~~~~~~~~r(H, K_{\lambda}) = \frac{\sum_{j=1}^{r} \frac{\eta_j}{\lambda + \eta_j}z_j^2}{\sqrt{\sum_{j=1}^{r} \left(\frac{\eta_j}{\eta_j+\lambda}\right)^2} \sum_{i=1}^n  y_i^2}.$


---
## Mantel Test

#### Correlation of Similarities

Assume $\text{rank}(X) = r$ with singular value decomposition $X = U_{n\times r}D_{r\times r}V_{p\times r}^T$, where $\eta_j, j = 1, \cdots, r$ are the squared singular values. 
Let $H=YY^T$ and $Z = U^TY$.

__Euclidean Metric__ $~~~~~~~~~~~~r(H, K_R) \asymp \sum_{j=1}^r\eta_j z_j^2 ~~~~~= \text{tr}(HK_R) = T_R,$

__Mahalanobis Metric__ $~~~~~~~r(H, K_F) \asymp \sum_{j=1}^r z_j^2 ~~~~~~~~= \text{tr}(HK_F) = T_F,$
    	
__Ridge Similarity__ $~~~~~~~~~~~~~r(H, K_{\lambda}) ~\asymp \sum_{j=1}^{r} \frac{\eta_j}{\lambda + \eta_j}z_j^2 ~= \text{tr}(HK_{\lambda}) = T_{\lambda}.$


---
## Mantel Test

#### Linear Model Definitions

$$\begin{aligned}
\hline
\text{Model Name}    & ~~~~~~\text{Definition} \\
\hline
\text{Random Eff.} & ~~~~~~~~Y \sim N(0, \sigma^2_b G + \sigma_{\varepsilon}^2 I_N), ~~~ G = XX^T/p\\
\text{Fixed Eff.} & ~~~~~~~~Y \sim N(X\beta, \sigma_{\varepsilon}^2 I_N)\\
\text{Ridge Reg.} & ~~~~~~~~Y \sim N(X\beta, \sigma_{\varepsilon}^2 I_N), ~~~~~~~~~~~~ \|\beta\|_2^2 < c(\lambda)\\
\hline
\end{aligned}$$

#### Linear Model Score Tests

$$\begin{aligned}
\hline
\text{Model}    & ~~~~~~~\text{Score Stat.} & \text{Equivalent Stat.} & ~~~~~~~\text{Null Distribution} \\
\hline
\text{Random Eff.} & ~~~~~~~~S_F = Z^T D(D^TD)^{-1}D^T Z & T_F = \text{tr}(K_F H) & ~~~~~~~~c\chi_p^2\\
\text{Fixed Eff.} & ~~~~~~~~S_R = Z^TDD^TZ & T_R = \text{tr}(K_R H) & ~~~~~~~\sum_{j = 1}^r \eta_j \chi_1^2\\
\text{Ridge Reg.} & ~~~~~~~~S_{\lambda} = Z^T D(D^TD + \lambda)^{-1}D^T Z & T_{\lambda} = \text{tr}(K_{\lambda}H) & ~~~~~~~\sum_{j=1}^{r}\frac{\eta_j}{\lambda+\eta_j} \chi_1^2\\
\hline
\end{aligned}$$

---
## Mantel Test

#### Limiting Relationship

From the previous results, we get the following limiting relationships between the ridge test, and tests for the fixed effects and random effects models.

$$T_{\lambda = 0} = T_F$$

$$T_{\lambda} \asymp \left\{\lambda \sum_{j=1}^{r}\frac{\eta_j}{\lambda+\eta_j}z_j^2\right\} ~~~\overset{\lambda \rightarrow \infty} \rightarrow~~ T_R$$

Similarly, for the matrix correlations

$$r(H, K_{\lambda = 0}) = r(H, K_F)$$

$$\lim_{\lambda \to \infty} r(H, K_{\lambda}) = r(H, K_R)$$

---
## Mantel Test

#### Proportion of Variance Explained 

$$R^2(X, Y)=\sqrt{p} \cdot r(H, K_F)$$
For large $n$ and assuming that $\text{rank}(X)=p$,<br><br>

$$\hat h_{MOM}^2=\frac{tr(HG)-n}{tr(G^2)-n}\approx p\sqrt{\frac{tr(H^2)}{\text{tr}(K_R^2)}}r(H,K_R)\in [r(H,K_R), \sqrt{p}\cdot r(H,K_R)]$$


---
## Linear Model Score Tests

#### Geometric Interpretation

Consider $Z = U^TY$, as the projection of $Y$ into the column space of $X$.  

1. The _Random Effects_ model tests the __weighted Euclidean norm__ of $Z$, where the $j$th component is weighted by the $j$th eigenvalue $\eta_j$.

2. The _Fixed Effects_ model tests the __Euclidean norm__ of $Z$

3. The _Ridge Penalization_ __weights the Euclidean norm of $Z$ proportional to the eigenvalues__, but these weights are now __flattened__ by a factor of $(\lambda + \eta_j)^{-1}$.



---
## Multivariate Mantel

* For the case of __multivariate response__, i.e. $Y$ is an $n \times q$ response matrix, we can define the similarity matrices

$$K = X(X^TX)^{-1}X^T$$
$$H = Y(Y^TY)^{-1}Y^T.$$

- When both $X$ and $Y$ are high dimensional it may make sense to use penalties for both, giving Gram matrices

$$H_{\lambda_y}=Y(Y^TY+\lambda_y I_q)^{-1}Y^T \mbox{ , }$$
$$K_{\lambda_x}=X(X^TX+\lambda_x I_p)^{-1}X^T.$$

- We can also use the $L_2$ similarity for both:

$$H = YY^T$$
$$K = XX^T$$

---
background-image:
class: center, middle, inverse

# Adaptive Mantel Test

---
## Adaptive Mantel Test

.full-width[.content-box-red[__Choosing a good penalty term for inference can be difficult, since we must control the type I error.__]]

#### Interpretation of $\lambda$

- The best linear unbiased predictors for the regression coefficients in the random effects model result from $\lambda = \frac{\sigma^2_{\varepsilon}}{\sigma^2_b}$ as a ridge penalty term.

- Since the noise to signal ratio can be calculated from $h^2$, a "reasonable" range for $\lambda$ can be determined from a range for $h^2$

$$\lambda = \frac{p(1 - h^2)}{h^2}.$$
    
---
## Adaptive Mantel Test
.full-width[.content-box-green[__Idea__<br><br>To simultaneously test a set of tuning parameters, use the __minimum__ _P_-__value__ across all parameters as 
the test statistic, and approximate the reference distribution using permutations.]]

#### Algorithm
- __Input:__ 
    + $X, n \times p$ covariates, column centered and scaled
    + $Y, n\times 1$ response, centered and scaled
    + $\left\{\left(\mathcal{K}_m^{\textbf{X}}, \mathcal{K}_m^{\textbf{Y}}\right)\right\}, m = 1, \cdots, M$
    
- __Output:__ $P_{ADA}$ = adaptive Mantel $P$-value for global test of significant association

- __Package available at [github.com/dspluta/adamant](https://github.com/dspluta/adamant)__

---
## Adaptive Mantel Test

#### Algorithm

.shadow[
```{r echo=FALSE}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/adamant_algorithm.png")
```
]

---
background-image: url("img/simulation_sparsity_plot.png")
background-size: contain
class: center, inverse

---
background-image:
class: center, inverse, middle

# Applications of the Adaptive Mantel Test

---
background-image: url(img/vwm_schematic_small.png)
background-size: fill
class: center, inverse

## Visual Working Memory Experiment

---
background-image: url(img/vwm_schematic_annotated_small.png)
background-size: fill
class: center, inverse

## Visual Working Memory Experiment

---
background-image: url(img/two_eeg_chans_plot.png)
background-size: contain
class: center, inverse

## Visual Working Memory Experiment

---
## Related Previous Results

- _Sauseng et al. (2005)_ also found that __theta__ and __alpha coherence__ play a significant role in “top-down” control during working memory tasks

- _Jiang et al. (2005)_ A study of EEG power and coherence in patients with mild cognitive impairment revealed 
differences in __theta, alpha, and beta band__ power between MCI and normal controls during working memory tasks.

- _Zhang et al. (2007)_ Found that __polymorphisms in a dopamine receptor gene affect neuronal activity__ during working memory.

- _Vogler et al. (2014)_ __Estimated SNP-based heritability for working memory performance__ to be in the range of $h^2 = 0.31$ to $0.41 (P = 0.0008$).

- _Cassidy et al. (2016)_ detected relationships between __dynamic connectivity__ during __working memory__ tasks and __dopamine release in schizophrenics__.

- _Dai et al. (2017)_ found topological reorginzation of EEG cortical __connectivity in the theta and alpha bands__ during working memory tasks.

---
background-image: url(img/brain_vwm.jpg)
background-size: contain
class: center, inverse

---
## SNPs Related to Alzheimer's Disease

#### Info on SNPs from [SNPedia](https://www.snpedia.com/index.php/Alzheimer%27s_disease):

- _rs2227564_: A functional polymorphism within plasminogen activator urokinase (PLAU) which some studies have shown to be associated with Alzheimer's disease. _(Riemenschneider et al., 2006)_
  
- _rs3851179_: A slight protective effect of the (A) allele of this SNP was found in _(Carasquillo et al., 2010)_
  
- _rs3818361_:  A SNP associated with the complement component (3b/4b) receptor 1 CR1 gene. _(Carasquillo et al., 2010)_
  
- _rs9886784_: An intergenic SNP on chromosome 9, is reported to influence the risk for Alzheimer's disease; the odds ratio is 3.23 (CI: 1.79 - 5.84). _(Li et al., 2007)_


---
## Data Description

- 350 Subjects from the BNU data set

- ~10 minute 64 channel EEG recording during VWM task
  
  + Preprocessed according to standard pipeline
  
  + Coherence measures for each channel pair was calculated by the FFT, and grouped into 
  five frequency bands (in Hz): $\delta~(1 - 4), \theta~(4 - 8), \alpha~(8 - 16), \beta~(16 - 32), \gamma~(32+)$
  
- 13 SNPs selected for analysis, previously identified as potential factors for Alzheimer's disease risk
  
  + All 13 SNPs passed standard MAF and HWE quality control checks

---
## Adaptive Mantel Test Results

- Results of adaptive Mantel test for association of AD SNPs and EEG Coherence at particular frequency bands

- Used $L_2$ similarity for SNPs, and ridge kernel similarity for coherence, with penalty terms $\Lambda = \{0.5, 1, 5, 10, 100, 1000, \infty\}$ 
  
<br><br>

$$\begin{aligned}
\hline
\text{Band} & ~~~~\text{Channels} & ~~~~P-\text{value}\\
\hline
\beta & ~~~~\text{All} & 0.619\\
\beta & ~~~~\text{Frontal} & 0.517\\
\hline
\alpha & ~~~~\text{All} & ~~~~0.075\\
\alpha & ~~~~\text{Frontal} & ~~~~0.381\\
\hline
\theta & ~~~~\text{All} & ~~~~0.416\\
\theta & ~~~~\text{Frontal} & ~~~~0.081\\
\hline
\delta & ~~~~\text{All} & 0.015\\
\delta & ~~~~\text{Frontal} & 0.088\\
\hline
\end{aligned}$$

---
background-image: url(img/theta.png)
background-size: contain
class: center, middle, inverse

---
background-image: url(img/alpha.png)
background-size: contain
class: center, middle, inverse

---
background-image: url(img/beta.png)
background-size: contain
class: center, middle, inverse


---
class: center, middle, inverse
background-image: 

# Methods for Dynamic Connectivity Analysis

---
## Dynamic Connectivity

#### DFC for fMRI with Time-varying BOLD Phase Coherence

Calculate BOLD Phase Coherence Connectivity to obtain a $q \times q \times T$ dFC matrix.

- Computing Phase Coherence:
  
  + Estimate phase $\theta(j, t)$ of BOLD signals in area $j$ at time $t$ using Hilbert transform
  
  + Given phase of the BOLD signals, phase coherence between areas $q$ and $q'$ at time $t$ (denoted $dFC(q, q', t)$) is defined as
  
  $$dFC(q, q', t) = \cos(\theta(q, t) - \theta(q', t)).$$

- _Leading Eigenvector_ of each $dFC(t)$ is used to capture connectivity structures.

---
background-image: url(img/dfc.jpg)
background-size: contain
class: inverse

---
## Dynamic Connectivity

#### Studying FC Dynamics

- Compute time-versus-time matrix to represent functional connectivity dynamics (FCD), where each $FCD(t_x, t_y)$ measures the resemblance between the $dFC$ at times $t_x$ and $t_y$ using Pearson correlation or cosine similarity:

$$FCD(t_x, t_y) = \frac{\left\langle V_1(t_x),V_1(t_y)\right\rangle}{\|V_1(t_x)\|\|V_1(t_y)\|} \in [-1, 1].$$
  
- _FC States:_ detect discrete FC states with $k$-means clustering on the leading eigenvectors $V_1(t)$ across all time points and subjects.

- _Between group Comparisons:_ Group differences are tested using permutation-based paired t-test 

---
background-image: url(img/GrangerCausalityIllustration.svg)
background-size: contain
class: inverse, center

## Effective Connectivity

```{r echo=FALSE, out.height="90%", out.width="90%"}
#knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/GrangerCausalityIllustration.svg")
```

---
background-image: url(img/SF-VAR_original_schematic.png)
background-size: contain
class: inverse

## Switching Factor VAR for Dynamic Connectivity

---
background-image: url(img/eegF2001_winsize32.png)
background-size: contain
class: inverse

---
## Multi-subject Dynamic Connectivity Modeling

### Possible Extension of switching factor VAR Model

1. Fit TV-VAR for each subject and compute time series of PDC matrices.

2. Apply $K$-means or HOSVD to concatenated PDC time series of all subjects.

3. Possibly refit and smooth with SVAR as before (or consider alternative ways of encouraging smoothness) 

4. Conduct heritability analysis on things like:

  - transition probabilities between states
  - proportion of time spent in a particular state
  - frequency of a state during certain phases of the experiment


---
class: center, middle, inverse
background-image: 

# Manifold Regression

---
## Manifold Regression

.pull-left[.full-width[.content-box-green[__Riemannian Manifold__<br><br>A smooth surface such that each point has a locally Euclidean neighborhood.]]]
.pull-right[
```{r echo=FALSE, out.height="80%", out.width="80%"}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/End_of_universe.jpg")
```
]

#### Some Manifolds of Interest

1. $\text{Sym}^+(q)$, $q \times q$ __positive definite matrices__

2. $O(q)$ and  $SO(q)$, the groups of __orthogonal__ and __special orthogonal__ $q \times q$  matrices

3. __Stiefel Manifold__, $q \times k$ matrices of orthonormal vectors.


---
background-image: 
class: center, inverse

## Positive Definite Cone

```{r echo=FALSE, out.height="80%", out.width="80%"}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/pd_cone.png")
```

---
## Manifold Regression

#### Specification of the Geodesic Model

- Suppose a $q \times q$ PD matrix $S_i \in \text{Sym}^+(q)$ and a $k \times 1$ vector of covariates are observed for each subject $i = 1, \cdots, n$.

- Let $\beta \in \mathbb{R}^p$ be a $p \times 1$ vector of regression coefficients

- $\Sigma(\cdot, \cdot): \mathbb{R^k}\times\mathbb{R^p} \to \text{Sym}^+(q)$. 

- We are interested in modeling the __conditional mean__ of $S_i$ given $x_i$, denoted 

$$\Sigma_i(\beta) = \Sigma(x_i, \beta) \in \text{Sym}^+(q).$$  

---
## Manifold Regression

#### Specification of the Geodesic Model

- Further let:
  + $D \in \text{Sym}^+(q)$ be the intercept matrix $D = \Sigma(0, \beta)$, with $D = BB^T$ for some $B \in GL(q)$
  + $Y_D(x_i, \beta) = Y_{D, i} \in \text{Sym}(q)$ be a "directional" matrix
  + $C_i(\beta)$ be a Cholesky square root $\Sigma(x_i, \beta) = C_i(\beta)C_i(\beta)^T$. 
 
- The __geodesic model__ is given by

$$\Sigma(x_i, \beta) = B\exp(B^{-1}Y_{D, i}(\beta)B^{-T})B^T = C_i(\beta)C_i(\beta)^T.$$

---
## Manifold Regression

- The __geodesic model__ is given by

$$\Sigma(x_i, \beta) = B\exp(B^{-1}Y_{D, i}(\beta)B^{-T})B^T = C_i(\beta)C_i(\beta)^T.$$

- The __residuals__ are defined as 

$$\mathcal{E}_i(\beta) = \log(C_i(\beta)^{-1}S_iC_i(\beta)^{-T}).$$

The intrinsic regression model is then specified by $\mathbb{E}[\mathcal{E}_i(\beta) | x_i] = 0$, where the intrinsic least squares estimate of $\beta$ is defined as 

$$\hat \beta = \arg\min_{\beta}\sum_{i = 1}^n \text{tr}\left(\mathcal{E}_i(\beta)^2\right).$$


---
background-image: 
class: inverse

## Manifold Regression

#### Geodesic Model

```{r echo=FALSE, out.height="90%", out.width="90%"}
knitr::include_graphics("/home/dustin/Dropbox/Research/uci-advancement/img/zhu_geodesic_manifold.jpg")
```

---
## Manifold Regression

#### Manifold Mixed Effects Model

- Kim et al. (2017) have proposed an extension of the linear mixed effects model to manifold-valued responses.  

- Let $Y_{[ij]}, B, B_i \in \mathcal{M}, V \in T_B\mathcal{M}^p, U_i \in T_{h[ij]}\mathcal{M}^q, x_{[ij]}\in \mathbb{R}^p, z_{[ij]} \in \mathbb{R}^q$, and let $\Gamma_{B \to B_i}V$ be the parallel transport of $V$ from $B$ to $B_i$.  

- A simplified form of the __manifold mixed effects model__ can be stated as

$$Y_{[ ij ]} = \text{Exp}(\text{Exp}(B_i, \Gamma_{B\to B_i} (V)x_{[ij]}, \varepsilon_{[ij]}))$$
$$B_i = \text{Exp}(B, U_i).$$

$$\Gamma_{B \to I} U_i ~\sim~ \mathcal{N}_{SYM}(0, \sigma_U^2),$$

where $\mathcal{N}_{SYM}$ is the normal distribution over symmetric positive definite matrices.

---
## Manifold Regression

#### Heritability Estimation for Manifold-valued Phenotype

- Analagous to the definition of the variance components model for heritability analysis, we propose a random effects model for manifold-valued phenotypes

- For this model, we instead consider the random effects $U_i$ to have a common aggregate genetic effect $\sigma^2_U$

$$\Gamma_{B \to I} U ~\sim~ \mathcal{N}_{SYM}(0, \sigma^2_U G)$$

---

### Links

- __Adaptive Mantel Test Paper:__ [arxiv.org/pdf/1712.07270.pdf](https://arxiv.org/pdf/1712.07270.pdf)

- __Slides available:__ [github.com/dspluta/Presentations/](https://github.com/dspluta/Presentations/)

- __Adaptive Mantel `R` Package:__ [github.com/dspluta/adamant](https://github.com/dspluta/adamant)


---
# References

* Wu M., et al. Kernel Machine SNP-set Testing under Multiple Candidate Kernels. Genetic Epideomiology. 2013. 37(3): 267-275.

* Cai T., et al., Kernel Machine Approach to Testing the Significance of Multiple Genetic Markers for Risk Prediction. Biometrics. 2011. 67(3): 975-986.

* Ge T, et al. Massively Expedited Genome-Wide 
Heritability Analysis (MEGHA). PNAS. 2015. 112, 
2479-2484.

* Xue G, et al. Functional Dissociations of Risk 
and Reward Processing in the Medial Prefrontal 
Cortex. Cerebral Cortex. 2009. 19, 1019-1027.

* Yang J, et al. GCTA: A Tool for Genome-wide Complex 
Trait Analysis. The American Journal of Human Genetics. (2011) 88, 76-82.

* Tzeng et al. (2009) Biometrics 65, 822.

* Visscher et al. (2014) Statistical power to detect genetic (co)variance of complex traits using SNP data. PLoS Genetics.

* GCTA Power, http://cnsgenomics.com/shiny/gctaPower/

---
count: false
# Appendix

---
count: false
## Adaptive Mantel Test

Computing the adaptive Mantel test can be done efficiently using either the SVD or a linear algebra 
trick, depending on the relative sizes of $n$ and $p$.

### SVD

- Computing the SVD $X = UDV^T$ can be completed in $O(np^2)$.

- When $rank(X) = r \leq n$, the Mantel statistic can be then be computed in $O(n^2)$:

$$T = \sum_{i = 1}^r \eta_i z_i^2$$

- Using $B$ permutations gives a total complexity of $O(np^2 + Bn^2)$.

---
count: false
## Adaptive Mantel Test

### Linear Algebra Trick

When $p \gg n$, it is better to instead use the following reformulation for $K$:

$$K_{\lambda} = X(X^TX + \lambda I_p)^{_1} = (XX^T + \lambda I_n)^{-1}XX^T.$$

Calculating $K_{\lambda}$ with this alternative form can be done in $O(n^2p)$, 
giving a total computational cost of $O\left(n^2(p + B)\right)$.

- The computation for the adaptive test scales this cost linear relative the number 
of tuning parameters included.

- The computations can be easily parallelized.

---
count: false
## EEG Pre-processing

  - __EEG pre-processing:__
      1. Downsample from 1024 Hz to 128 Hz
      2. Remove bad channels
      3. Band-pass filter from 1 Hz to 45 Hz
      4. Interpolate/re-reference bad channels
      5. ICA to remove eyeblinks and motion artifacts
      6. Remove remaining bad trials.  Exclude subjects if > 5% of trials removed.
      
  - __Calculate coherence__ for all subjects and all channels using the FFT, and compute 
  mean coherence by frequency band.



---
count: false
## Most Significant Channel Pairs for $h^2$

```{r, echo = FALSE}
DT::datatable(dat_results %>% filter(band == 2 | band == 3, Pval < 0.015) %>% 
                transmute(Pval = round(Pval, 4), h2 = round(h2, 4), band = c("delta", "theta", "alpha", "beta", "gamma")[band],
                          chan1 = chan1_name, chan2 = chan2_name))
```

---
count: false
# Estimating Heritability with GCTA

* While GCTA is a sensible and feasible approach to 
estimating heritability, it may prove impractical due to sample size limitations.

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;margin:0px auto;}
.tg td{font-family:Arial, sans-serif;font-size:16px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-yw4l{vertical-align:top}
</style>
<br>
<table class="tg">
  <tr>
    <th class="tg-yw4l">Sample Size</th>
    <th class="tg-yw4l">Heritability $h^2$</th>
    <th class="tg-yw4l">Power</th>
    <th class="tg-yw4l">$SE(\hat h^2)$</th>
  </tr>
  <tr>
    <td class="tg-yw4l">1000</td>
    <td class="tg-yw4l">0.2</td>
    <td class="tg-yw4l">0.097</td>
    <td class="tg-yw4l">0.316</td>
  </tr>
  <tr>
    <td class="tg-yw4l">2000</td>
    <td class="tg-yw4l">0.2</td>
    <td class="tg-yw4l">0.24</td>
    <td class="tg-yw4l">0.158</td>
  </tr>
  <tr>
    <td class="tg-yw4l">3000</td>
    <td class="tg-yw4l">0.2</td>
    <td class="tg-yw4l">0.475</td>
    <td class="tg-yw4l">0.105</td>
  </tr>
  <tr>
    <td class="tg-yw4l">1000</td>
    <td class="tg-yw4l">0.5</td>
    <td class="tg-yw4l">0.353</td>
    <td class="tg-yw4l">0.316</td>
  </tr>
  <tr>
    <td class="tg-yw4l">2000</td>
    <td class="tg-yw4l">0.5</td>
    <td class="tg-yw4l">0.885</td>
    <td class="tg-yw4l">0.158</td>
  </tr>
  <tr>
    <td class="tg-yw4l">3000</td>
    <td class="tg-yw4l">0.5</td>
    <td class="tg-yw4l">0.997</td>
    <td class="tg-yw4l">0.105</td>
  </tr>
  <tr>
    <td class="tg-yw4l">400</td>
    <td class="tg-yw4l">1</td>
    <td class="tg-yw4l">---</td>
    <td class="tg-yw4l">0.79</td>
  </tr>
  <caption> Power calculations for GCTA model.</caption>
</table>

.footnote[http://cnsgenomics.com/shiny/gctaPower/]


---
## Multivariate Mantel

__Hooper's trace correlation__ (Hooper 1959) is defined as 

$$r_T^2 = \frac{1}{q}\text{tr}\left((Y^TY)^{-1}Y^TX(X^TX)^{-1}X^TY)\right)$$
The relationship between Hooper's trace correlation and $r(H_F,K_F)$ follows from $\text{tr}(H_F) = q, \text{tr}(K_F) = p$:

$$r_T^2 = \sqrt{\frac{p}{q}}r(H_F, K_F).$$

---
## Multivariate Mantel

#### Multivariate Heritability

Following Ge et al. (2016), a multivariate version of $h^2$ can be defined

$$h^2 = \frac{\text{tr}(\Sigma_g)}{\text{tr}(\Sigma_g) + \text{tr}(\Sigma_{\varepsilon})}.$$
A method of moments estimator for $h^2$ is

$$\hat h^2_{MOM}=\frac{tr(K_R)tr(\hat \Sigma_b)}{tr(H_R)}=\frac{tr(K_R)}{tr(H_R)} \frac{tr(H_RK_R)-tr(H_R)tr(K_R)/n}{tr(K_R^2)-tr^2(K_R)/n}.$$

When both $X$ and $Y$ are column-standardized and full column rank it can be shown that

$$\hat h^2_{MOM}\in \left[\frac{1}{\sqrt{q}}r(H_R,K_R),\sqrt{p}~r(H_R,K_R)\right]$$

---
## Multivariate Mantel

.full-width[.content-box-yellow[__Interpretation of Tuning Parameters__<br><br>In general, a large tuning parameter __reduces the adjustment for the correlation between features__, and so approaches the use of __Euclidean distance__ in that modality as the parameter increases.]]

#### Limiting Relationships

$$\lim _{\lambda_x\rightarrow 0, \lambda_y\rightarrow 0} r(H_{\lambda_y},K_{\lambda_x})=r(H_F, K_F)$$
$$\lim _{\lambda_x\rightarrow \infty, \lambda_y\rightarrow \infty} r(H_{\lambda_y},K_{\lambda_x})=r(H_R, K_R)$$

#### Penalized Likelihood

$$-\ell \propto c_1 log|\Sigma_e| + tr[(Y-XB)\Sigma_e^{-1}(Y-XB)^T] + \lambda_x tr[B\Sigma_e^{-1}B^T] + \lambda_y tr[\Sigma_e^{-1}] + c_2$$

<!-- - $\lambda_x$ shrinks $B$ toward zero: similar to the univariate case, we can replace $X(X^T+\lambda_x I_p)^{-1}X^T$ with $XX^T$ when $\lambda_x$ is large. -->

<!-- - $\lambda_y$ encourages smaller sums of the reciprocals of the eigenvalues of $\Sigma_{\varepsilon}$, thus when $\lambda_y$ is large, $\Sigma_e$ is approximately proportional to the identity matrix. -->


---
background-image: 
background-position: center
background-size: contain

## AdaMant Package

```{r, cache = TRUE, warning = FALSE, message = FALSE}
set.seed(1234)
X <- matrix(rnorm(500), nrow = 50, ncol = 10)
Y <- X %*% rep(c(0, 0.6), 5) + rnorm(50, 0, 2)

adamant(X, Y, lambdas_X = c(0, 1, 10, Inf),   
        n_perms = 2000, P_val_only = TRUE)
```
